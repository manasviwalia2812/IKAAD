# Evaluation Metrics â€“ IKAAD

## Objectives

Evaluate accuracy, grounding, and reliability of AI-generated responses.

## Metrics

### Grounding Score
- Measures overlap between generated response and retrieved context

### Retrieval Relevance
- Based on vector similarity scores

### Response Latency
- Time from query submission to response generation

### Hallucination Detection
- Flags responses when retrieval confidence is low

## Comparative Evaluation

- LLM-only vs RAG-based responses
- Used to demonstrate hallucination reduction
